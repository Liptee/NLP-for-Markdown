{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как с помощью Pyhton и NLTK извлечь ключевые слова (не самые частые слова) из корпуса?\n",
    "[Ссылка на статью](https://www.stackfinder.ru/questions/43662428/how-do-i-pull-key-words-not-most-frequent-words-out-of-a-corpus-using-python-a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я пытаюсь извлечь ключевые слова из текста или корпуса. Это не самые частые слова, но слова, которые больше всего относятся к тексту. У меня есть сравнительный пример, и список, который я создаю, сильно отличается от списка примеров. Не могли бы вы дать мне указатель на создание хорошего списка ключевых слов, который не включает в себя такие малозначимые слова, как «thou» и «tis»?\n",
    "\n",
    "В качестве текста я использую «Ромео и Джульетту». Мой подход (см. «Скотт и Триббл» ниже) состоит в том, чтобы сравнить R&J с полными пьесами Шекспира и вытащить слова, которые встречаются в R&J значительно чаще, чем в полных пьесах. Это должно отсеять частые слова вроде «the», но в моем коде этого не происходит.\n",
    "\n",
    "Я получаю много таких слов, как «ты», «она» и «это», которых нет в их списке, и я НЕ получаю таких слов, как «изгнанный» и «кладбище». Я получаю «ромео», «джульетту», «капулетти» и «медсестру», так что я, по крайней мере, близок к правильному пути, если не на самом деле.\n",
    "\n",
    "Вот функция, которая извлекает слова и проценты из текстов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords(corpus, threshold=0):\n",
    "    \"\"\" generates a list of possible keywords and the percentage of \n",
    "           occurrences.\n",
    "          corpus (list): text or collection of texts\n",
    "          threshold (int): min # of occurrences of word in corpus                    \n",
    "              target text has threshold 3, ref corp has 0\n",
    "          return percentKW: list of tuples (word, percent)                         \n",
    "    \"\"\"\n",
    "\n",
    "    # get freqDist of corpus as dict. key is word, value = # occurences\n",
    "    fdist = FreqDist(corpus)\n",
    "    n = len(corpus)\n",
    "\n",
    "    # create list of tuple of w meeting threshold & sort w/most common first\n",
    "    t = [(k, v) for k, v in fdist.items() if v >= threshold]\n",
    "    t = sorted(t, key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "    # calculate number of total tokens\n",
    "    n = len(corpus)\n",
    "\n",
    "    # return list of tuples (word, percent word is of total tokens)\n",
    "    percentKW =[(k, '%.2f'%(100*(v/n))) for k, v in t]\n",
    "    return percentKW"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
