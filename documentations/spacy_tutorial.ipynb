{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Можно всё: решение NLP задач при помощи spacy\n",
    "[Оригинал](https://habr.com/ru/post/531940/?ysclid=l4pocupcuc912622060)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Базовые операции\n",
    "Прежде чем начинать работу с текстом, следует импортировать языковую модель. Для русского языка существует официальная модель от SpaCy, поддерживающая токенизацию (разбиение текста на отдельные токены) и ряд других базовых операций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.ru import Russian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После импорта и создания экземпляра языковой модели можно начинать обработку текста. Для этого нужно всего лишь передать текст созданному экземпляру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Russian()\n",
    "doc = nlp(\"Съешь ещё этих мягких французских булок, да выпей чаю.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Работа с получившимся объектом Doc очень схожа с работой со списками: можно обращаться к нужному токену по индексу или делать срезы из нескольких токенов. А чтобы получить текст токена или среза, можно использовать атрибут text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Съешь\n",
      "мягких французских булок\n"
     ]
    }
   ],
   "source": [
    "token = doc[0]\n",
    "print(token.text)\n",
    "\n",
    "span = doc[3:6]\n",
    "print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для получения дополнительной информации о том, какой тип информации содержится в токене, можно использовать следующие атрибуты:\n",
    "1. is_alpha – проверка на то, содержит ли токен только буквенные символы\n",
    "2. is_punct – проверка на то, является ли токен знаком пунктуации\n",
    "3. like_num – проверка на то, является ли токен числом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_alpha:     [True, True, True, True, True, True, False, True, True, True, False]\n",
      "is_punct:     [False, False, False, False, False, False, True, False, False, False, True]\n",
      "like_num:     [False, False, False, False, False, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(\"is_alpha:    \", [token.is_alpha for token in doc])\n",
    "print(\"is_punct:    \", [token.is_punct for token in doc])\n",
    "print(\"like_num:    \", [token.like_num for token in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим ещё пример, где на экран выводятся все токены, предшествующие точке. Чтобы получить такой результат, при переборе токенов следует делать проверку следующего токена, используя атрибут token.i:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "чаю\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.i+1 < len(doc):\n",
    "        next_token = doc[token.i+1]\n",
    "        if next_token.text == \".\":\n",
    "            print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Операции с синтаксисом\n",
    "Для более сложных операций по обработке текста используются другие модели. Они специально натренированы для задач, связанных с синтаксисом, выделением именованных сущностей и работы со значениями слов. Например, для английского языка существует 3 официальных модели, различающихся размером. Для русского языка на настоящий момент официальная модель ещё не обучена, однако уже есть модель ru2 из сторонних источников, которая умеет работать с синтаксисом.\n",
    "\n",
    "В конце этой статьи мы разберём, как создавать свои собственные модели или дополнительно обучать существующие, чтобы они лучше работали для конкретных задач.\n",
    "\n",
    "Чтобы полностью проиллюстрировать возможности SpaCy, в этой статье мы будем использовать модели для английского языка. Давайте установим маленькую модель `en_core_web_sm`, которая отлично подойдёт для демонстрации возможностей. Для её установки в командной строке необходимо набрать:\n",
    "```cmd\n",
    "python -m spacy download en_core_web_sm\n",
    "```\n",
    "С использованием этой модели мы можем для каждого из токенов получить часть речи, роль в предложении и токен, от которого он зависит:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New         PROPN     compound  MacBook     \n",
      "Apple       PROPN     compound  MacBook     \n",
      "MacBook     PROPN     nsubj     set         \n",
      "set         VERB      ROOT      set         \n",
      "launch      NOUN      dobj      set         \n",
      "tomorrow    NOUN      npadvmod  set         \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"New Apple MacBook set launch tomorrow\")\n",
    "\n",
    "for token in doc:\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    token_head = token.head.text\n",
    "    print(f\"{token_text:<12}{token_pos:<10}\" \\\n",
    "        f\"{token_dep:<10}{token_head:<12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несомненно, лучший способ увидеть зависимости – не вчитываться в текстовые данные, а построить синтаксическое дерево. В этом может помочь функция displacy, которой нужно просто передать документ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"482085e8d8ee4b98b0fb3862b50d5949-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">New</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">MacBook</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">set</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">launch</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">tomorrow</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-482085e8d8ee4b98b0fb3862b50d5949-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-482085e8d8ee4b98b0fb3862b50d5949-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-482085e8d8ee4b98b0fb3862b50d5949-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-482085e8d8ee4b98b0fb3862b50d5949-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-482085e8d8ee4b98b0fb3862b50d5949-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-482085e8d8ee4b98b0fb3862b50d5949-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-482085e8d8ee4b98b0fb3862b50d5949-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-482085e8d8ee4b98b0fb3862b50d5949-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-482085e8d8ee4b98b0fb3862b50d5949-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-482085e8d8ee4b98b0fb3862b50d5949-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для расшифровки названий тегов можно воспользоваться функций `explain`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auxiliary\n",
      "proper noun\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"aux\"))\n",
    "print(spacy.explain(\"PROPN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь на экран выводятся расшифровки аббревиатур, из которых мы можем узнать, что aux обозначает вспомогательную частицу (auxiliary), а PROPN – имя собственное (proper noun).\n",
    "\n",
    "В SpaCy также реализована возможность узнать начальную форму слова для любого из токенов (для местоимений используется -PRON-):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I see a movie yesterday\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I saw a movie yesterday\")\n",
    "print(' '.join([token.lemma_ for token in doc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выделение именованных сущностей\n",
    "Часто для работы с текстом требуется выделить сущности, упомянутые в тексте. Чтобы получить список именованных сущностей в документе, используется атрибут doc.ents, а для получения метки для этой сущности – атрибут ent.label_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "1$ billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Apple is looking at buying U.K. startup for 1$ billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь также можно использовать атрибут `explain`, чтобы узнать расшифровки меток именованных сущностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries, cities, states\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"GPE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А функция `displacy` поможет наглядно обозначить списки сущностей прямо в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is looking at buying \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " startup for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1$ billion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание собственных шаблонов для поиска текста\n",
    "Модуль spaCy содержит очень полезный инструмент, который позволяет строить свои собственные шаблоны для поиска текста. В частности, можно искать слова определённой части речи, все формы слова по его начальной форме, делать проверку на тип содержимого в токене.\n",
    "\n",
    "Давайте попробуем создать собственный шаблон для распознавания последовательности токенов. Допустим, мы хотим извлечь из текста строки про кубки мира FIFA или ICC Cricket с упоминанием года:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 ICC Cricket World Cup\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\"IS_DIGIT\": True}, \n",
    "    {\"LOWER\": {\"REGEX\": \"(fifa|icc)\"}},\n",
    "    {\"LOWER\": \"cricket\", \"OP\": \"?\"},\n",
    "    {\"LOWER\": \"world\"},\n",
    "    {\"LOWER\": \"cup\"}\n",
    "]\n",
    "matcher.add(\"fifa_pattern\", [pattern])\n",
    "doc = nlp(\"2018 ICC Cricket World Cup: Afghanistan won!\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    matched_span = doc[start:end]\n",
    "    print(matched_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, в этом блоке кода мы импортировали специальный объект Matcher, позволяющий хранить набор пользовательских шаблонов. После его инициализации мы создали шаблон, где указали последовательность токенов. Обратите внимание, что для выбора между ICC и FIFA мы использовали регулярные выражения, а для токена Cricket – ключ, указывающий на необязательность наличия этого токена.\n",
    "\n",
    "После создания шаблона требуется добавить его к набору с помощью функции add, указав в параметрах уникальный ID шаблона. Результаты поиска представлены в форме списка кортежей. Каждый из кортежей состоит из ID совпадения, а также начального и конечного индексов найденного в документе среза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение семантической близости\n",
    "Два слова могут быть очень схожи по смыслу, но как измерить их близость? В подобных задачах на помощь могут прийти семантические вектора. Если два слова или многословных выражения похожи, то их вектора будут лежать близко друг к другу.\n",
    "\n",
    "Посчитать семантическую близость векторов в SpaCy несложно, если языковая модель была обучена для решения таких задач. Результат сильно зависит от размера модели, поэтому для этой задачи возьмём модель побольше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9216289746754729\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc1 = nlp(\"I like burgers\")\n",
    "doc2 = nlp(\"i like pizza\")\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение может колебаться от нуля до единицы: чем ближе к единице, тем больше схожесть. В примере выше мы сравнивали два документа, однако точно так же можно сравнивать отдельные токены и срезы.\n",
    "\n",
    "Оценка семантической близости может быть полезна при решении множества задач. Например, с её помощью можно настроить рекомендательную систему, чтобы она предлагала пользователю похожие тексты на основе уже прочитанных.\n",
    "\n",
    "Важно помнить, что семантическая близость очень субъективна и всегда зависит от контекста задачи. Например, фразы «я люблю собак» и «я ненавижу собак» похожи, поскольку обе выражают мнение о собаках, но в то же время сильно различаются по настроению. В некоторых случаях придётся дополнительное обучить языковые модели, чтобы результаты коррелировали с контекстом вашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание своих собственных компонентов обработки\n",
    "Модуль SpaCy поддерживает ряд встроенных компонентов (токенизатор, выделение именованных сущностей), но также позволяет определять свои собственные компоненты. По сути, компоненты – это последовательно вызывающиеся функции, которые принимают на вход документ, изменяют его и отдают обратно. Новые компоненты можно добавлять с помощью атрибута `add_pipe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <function length_component at 0x00000267A04AF2E0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\muzzo\\OneDrive\\Рабочий стол\\НИР 2\\spacy_tutorial.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000038?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000038?line=7'>8</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000038?line=8'>9</a>\u001b[0m nlp\u001b[39m.\u001b[39;49madd_pipe(length_component, first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000038?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(nlp\u001b[39m.\u001b[39mpipe_names)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000038?line=10'>11</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39m\u001b[39mThis is a sentence.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\muzzo\\.virtualenvs\\НИР_2-WuA8f2ou\\lib\\site-packages\\spacy\\language.py:773\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    771\u001b[0m     bad_val \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(factory_name)\n\u001b[0;32m    772\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE966\u001b[39m.\u001b[39mformat(component\u001b[39m=\u001b[39mbad_val, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    774\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m factory_name\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_names:\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <function length_component at 0x00000267A04AF2E0> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "def length_component(doc):\n",
    "    doc_length = len(doc)\n",
    "    print(f\"This document is {doc_length} tokens long.\")\n",
    "    return doc\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(length_component, first=True)\n",
    "print(nlp.pipe_names)\n",
    "doc = nlp(\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере выше мы создали и добавили собственную функцию, которая выводит на экран количество токенов в обрабатываемом документе. С помощью атрибута nlp.pipe_names мы получили порядок выполнения компонентов: как мы видим, созданный компонент первый в списке. Чтобы указать, куда добавить новый компонент, можно использовать следующие параметры:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](IMGS\\ghamimjpzw4z6pona_iwrz3xiwi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможность добавления пользовательских компонентов – очень мощный инструмент, позволяющий оптимизировать обработку под свои задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и обновление моделей\n",
    "Статистические модели делают прогнозы на основе тех примеров, на которых они обучались. Как правило, точность таких моделей можно улучшить, дополнительно обучив их на примерах, характерных для вашей задачи. Дополнительное обучение существующих моделей может быть очень полезно (например, для распознавания именованных сущностей или синтаксического анализа).\n",
    "\n",
    "Дополнительные примеры для обучения можно добавлять прямо в интерфейсе SpaCy. Сами примеры должны состоять из текстовых данных и списка меток для этого примера, на которых модель будет обучаться.\n",
    "\n",
    "В качестве иллюстрации рассмотрим обновление модели для извлечения именованных сущностей. Чтобы обновить такую модель, нужно передать ей множество примеров, которые содержат текст, указание на сущности и их класс. В примерах необходимо использовать целые предложения, поскольку при извлечении сущностей модель во многом ориентируется на контекст предложения. Очень важно всесторонне обучить модель, чтобы она умела распознавать токены, не являющиеся сущностями.\n",
    "\n",
    "Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Is that apple pie I smell?', {'entities': []})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\"What to expect at Apple's 10 November event\", {\"entities\": [(18,23,\"COMPANY\")]})\n",
    "(\"Is that apple pie I smell?\", {\"entities\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом примере упоминается компания: для обучения мы выделяем позиции, где начинается и заканчивается её наименование, а затем проставляем нашу метку о том, что эта сущность является компанией. Во втором примере речь идёт о фрукте, поэтому сущности отсутствуют.\n",
    "\n",
    "Данные для обучения модели обычно размечаются людьми, однако эту работу можно немного автоматизировать, используя собственные поисковые шаблоны в SpaCy или специализированные программы для разметки (например, Prodigy).\n",
    "\n",
    "После того, как примеры будут подготовлены, можно приступать непосредственно к обучению модели. Чтобы модель эффективно обучилась, нужно провести серию из нескольких обучений. С каждым обучением модель будет оптимизировать веса тех или иных параметров. Модели в SpaCy используют методику стохастического градиентного спуска, поэтому неплохим решением будет перемешивать примеры при каждом обучении, а также передавать их небольшими порциями (пакетами). Это увеличит надежность оценок градиента."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img1](IMGS\\vdagenff2stshmmogvjjqt_ehs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "minibatch() missing 1 required positional argument: 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\muzzo\\OneDrive\\Рабочий стол\\НИР 2\\spacy_tutorial.ipynb Cell 41'\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000047?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000047?line=13'>14</a>\u001b[0m     random\u001b[39m.\u001b[39mshuffle(TRAINING_DATA)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000047?line=14'>15</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m spacy\u001b[39m.\u001b[39;49mutil\u001b[39m.\u001b[39;49mminibatch(TRAINING_DATA):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000047?line=15'>16</a>\u001b[0m         texts \u001b[39m=\u001b[39m [text \u001b[39mfor\u001b[39;00m text, annotation \u001b[39min\u001b[39;00m batch]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000047?line=16'>17</a>\u001b[0m         annotations \u001b[39m=\u001b[39m [annotation \u001b[39mfor\u001b[39;00m text, annotation \u001b[39min\u001b[39;00m batch]\n",
      "\u001b[1;31mTypeError\u001b[0m: minibatch() missing 1 required positional argument: 'size'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.lang.en import English\n",
    "\n",
    "TRAINING_DATA = [\n",
    "    (\"What to expect at Apple's 10 November event\", \n",
    "    {\"entities\": [(18,23,\"COMPANY\")]})\n",
    "    # Другие примеры...\n",
    "]\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "for i in range(10):\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        nlp.update(texts, annotations)\n",
    "        \n",
    "nlp.to_disk(\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере выше цикл состоял из 10 обучений. После завершения обучения модель была сохранена на диск, в папку model.\n",
    "\n",
    "Для случаев, когда нужно не просто обновить, а создать новую модель, перед началом обучения требуется совершить ряд операций.\n",
    "\n",
    "Рассмотрим процесс создания новой модели для выделения именованных сущностей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x00000267B6DB3140> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\muzzo\\OneDrive\\Рабочий стол\\НИР 2\\spacy_tutorial.ipynb Cell 43'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000049?line=0'>1</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mblank(\u001b[39m\"\u001b[39m\u001b[39men\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000049?line=1'>2</a>\u001b[0m ner \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mcreate_pipe(\u001b[39m\"\u001b[39m\u001b[39mner\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000049?line=2'>3</a>\u001b[0m nlp\u001b[39m.\u001b[39;49madd_pipe(ner)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000049?line=3'>4</a>\u001b[0m ner\u001b[39m.\u001b[39madd_label(\u001b[39m\"\u001b[39m\u001b[39mCOMPANY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/muzzo/OneDrive/%D0%A0%D0%B0%D0%B1%D0%BE%D1%87%D0%B8%D0%B9%20%D1%81%D1%82%D0%BE%D0%BB/%D0%9D%D0%98%D0%A0%202/spacy_tutorial.ipynb#ch0000049?line=4'>5</a>\u001b[0m nlp\u001b[39m.\u001b[39mbegin_training()\n",
      "File \u001b[1;32mc:\\Users\\muzzo\\.virtualenvs\\НИР_2-WuA8f2ou\\lib\\site-packages\\spacy\\language.py:773\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    771\u001b[0m     bad_val \u001b[39m=\u001b[39m \u001b[39mrepr\u001b[39m(factory_name)\n\u001b[0;32m    772\u001b[0m     err \u001b[39m=\u001b[39m Errors\u001b[39m.\u001b[39mE966\u001b[39m.\u001b[39mformat(component\u001b[39m=\u001b[39mbad_val, name\u001b[39m=\u001b[39mname)\n\u001b[1;32m--> 773\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    774\u001b[0m name \u001b[39m=\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m factory_name\n\u001b[0;32m    775\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponent_names:\n",
      "\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.ner.EntityRecognizer object at 0x00000267B6DB3140> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "ner.add_label(\"COMPANY\")\n",
    "nlp.begin_training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('НИР_2-WuA8f2ou')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2e6c9fab53fc3211fd37e0beae5e4569e950ef80c5ec8c35b734107b47e84f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
