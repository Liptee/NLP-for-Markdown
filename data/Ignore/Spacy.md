[Оригинал]([Можно всё: решение NLP задач при помощи spacy / Хабр (habr.com)](https://habr.com/ru/post/531940/?ysclid=l4e79jyb7l310716187))
# Можно всё: решение NLP задач при помощи spacy

Обработка естественного языка сейчас используется повсеместно: стремительно развиваются голосовые интерфейсы и чат-боты, разрабатываются модели для обработки больших текстовых данных, продолжает развиваться машинный перевод.

В этой статье мы рассмотрим относительно новую библиотеку **Spacy**, которая на данный момент является одним из самых популярных и удобных решений при обработке текста в Python. Ее функционал позволяет решать широкий спектр задач: от определения частей речи и выделения именованных сущностей до создания собственных моделей для анализа.

Для начала давайте наглядно рассмотрим, как происходит обработка данных в **SpaCy**. Загруженный для обработки текст последовательно происходит через различные компоненты обработки и сохраняется как экземпляр объекта Doc:
![[Pasted image 20220614163654.png]]
Doc является центральной структурой данных в **SpaCy**, именно в нем хранятся последовательности слов или, как еще их называют токенов. Внутри объекта Doc можно выделить два других типа объекта: **Token** и **Span**. *Token* представляет собой ссылку на отдельные слова документа, а *Span* - ссылку на последовательность из нескольких слов (их можно создавать самостоятельно):
![[Pasted image 20220614163852.png]]
Еще одной важной структурой данных является объект *Vocab*, который хранит набор справочных таблиц, общий для всех документов. Это позволяет экономить память и обеспечивать единый источник информации для всех обрабатываемых документов.

Токены документов связаны с объектом *Vocab* через хэш, используя который можно получить начальные формы слов или другие лексические атрибуты токенов:
![[Pasted image 20220614164109.png]]
Теперь мы знаем, как устроено хранение и обработка данных в библиотеке SpaCy. А как воспользоваться возможностями, которые она предоставляет? Давайте последовательно рассмотрим операции, с помощью которых можно обработать текст.
## Базовые операции
Прежде чем начинать работу с текстом, следует импортировать языковую модель. Для русского языка существует официальная модель от *SpaCy*, поддерживающуя токенизацию (разбиение текста на отдельные токены) и ряд других базовых операций:
```python
from spacy.lang.ru import Russian
```
После импорта и создания экземпляра языковой модели можно начинать обработку текста. Для этого нужно всего лишь передать текст созданному экземпляру:
```python
nlp = Russian()
doc = nlp("Съешь вот эти французские булочки, да выпей чаю")
```
Работа с получившимся объектом `Doc` очень схожа с работой со списками: можно обращаться к нужному токену по индексу или делать срезы из нескольких токенов. А чтобы получить текст токена или среза, можно использовать атрибут `text`:
```python
token = doc[0]
print(token.text)

span = doc[3:6]
print(span.text)
```